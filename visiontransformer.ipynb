{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a763d7-4387-4e05-8c36-3ed8c7f54944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5bb42b9d50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aca00da-1ec0-4632-aa2a-f19b2342ce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #Loading data\n",
    "    transform = ToTensor()\n",
    "\n",
    "    train_set = MNIST(root='./../datasets', train=True, download=True, transform=transform)\n",
    "    test_set = MNIST(root='./../datasets', train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_set, shuffle=True, batch_size=128)\n",
    "    test_loader = DataLoader(test_set, shuffle=False, batch_size=128)\n",
    "\n",
    "    #Define model and training options\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device: \",device,f\" ({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else\"\")\n",
    "    model = MyViT((1, 28, 28), n_patches=7, n_blocks=2, hidden_d=8, n_heads=2, out_d=10).to(device)\n",
    "    N_EPOCHS = 5\n",
    "    LR = 0.005\n",
    "\n",
    "    #Training Loop\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    criterion = CrossEntropyLoss()\n",
    "    for epoch in trange(N_EPOCHS, desc=\"Training\"):\n",
    "        train_loss = 0.0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            loss = criterion(y_hat, y)\n",
    "\n",
    "            train_loss += loss.detach().cpu().item() / len(train_loader)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{N_EPOCHS} loss: {train_loss:.2f}\")\n",
    "\n",
    "    #Test loop\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0,0\n",
    "        test_loss = 0.0\n",
    "        for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "            x, y = batch\n",
    "            x, y =x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            loss = criterion(y_hat,y)\n",
    "            test_loss += loss.detach().cpu().item() / len(test_loader)\n",
    "\n",
    "            correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "            total += len(x)\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy:{correct / total * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73dadb56-4f3a-4dc1-9d99-a273d5689c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyViT(nn.Module):\n",
    "    def __init__(self):\n",
    "    #super(MyViT, self).__init__()\n",
    "        super(MyViT, self).__init__()\n",
    "    def forward(self, images):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4846de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patchify(images, n_patches):\n",
    "    n, c, h, w = images.shape\n",
    "\n",
    "    assert h == w, \"Patchf method is implemented for square images only\"\n",
    "\n",
    "    patches = torch.zeros(n, n_patches ** 2, h*w*c // n_patches ** 2)\n",
    "    patch_size = h // n_patches\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        for i in range(n_pathces):\n",
    "            for j in range(n_patches):\n",
    "                patch = image[:, i * patch_size:(i + 1) * patch_size, j * patch_size: (j + 1) * patch_size]\n",
    "                patches[idx, i * n_patches + j] = patch.flatten()\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4fe519",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyViT\n",
    "#try\n",
    "SS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
